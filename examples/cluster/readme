# RavenDB Cluster Bootstrapper

The **RavenDB Cluster Bootstrapper** runs inside the cluster as Kubernetes-native standalone job. Its purpose is to take an already deployed set of RavenDB nodes and automatically form a functional cluster without manual intervention.

 It is designed to run **after** the RavenDB Operator deploys the nodes, ensuring they are automatically discovered, verified, and joined into a functional cluster for both **Let's Encrypt** and **Self-Signed** certificate modes.

---

## Key Features

- **Automatic Node Discovery** â€“ Detects and verifies all RavenDB pods are running.
- **TLS Validation** â€“ Confirms HTTPS endpoints are live and present valid certificates.
- **Cluster Topology Setup** â€“ Adds members and watchers based on predefined configuration.
- **Dual Mode Support** â€“ Works with both Let's Encrypt-issued and self-signed TLS certificates.
- **Fail-Fast Logging** â€“ Provides clear, timestamped logs for each bootstrap step.

---

## How It Works

1. **Bootstrapper Job Creation**  
   The RavenDB operater create a short-lived `Job` that launches the bootstrapper container in the same namespace as the RavenDBCluster resource.

2. **Wait for Pod Readiness**  
   The bootstrapper waits until all RavenDB pods are in the `Running` state.

3. **Check HTTPS (Studio) Reachability**  
   Each node is tested for HTTPS connectivity.

4. **Install Client Certificate on Leader Node**  
   The bootstrapper uploads the provided client certificate to the leader node, ensuring it is registered and trusted for ClusterAdmin API authentication. This allows secure execution of cluster management operations such as adding nodes.

5. **Cluster Joining** 
   The bootstrapper connects to the **leader node** and sends cluster management API calls to add members and watchers.


6. **Validate Topology**  
   The final topology is retrieved and displayed, including:
   - Cluster leader
   - Members
   - Watchers
   - Topology ID

---


## Cluster Setup Configuration â€“ Let's Encrypt vs Self-Signed

When defining a `RavenDBCluster` resource, you first decide **how the cluster will be secured**, and based on that, configure **how nodes will join the topology**.
This involves selecting the TLS mode (**Let's Encrypt** or **Self-Signed**), specifying the cluster leader, and defining which nodes will act as watchers or members.  


Letâ€™s start with a **generic CR node setup** that defines the public URLs for each node in the cluster:

```yaml
spec:
  nodes:
    - tag: a
      publicServerUrl: https://a.example.development.run:443
      publicServerUrlTcp: tcp://a-tcp.example.development.run:443
    - tag: b
      publicServerUrl: https://b.example.development.run:443
      publicServerUrlTcp: tcp://b-tcp.example.development.run:443
    - tag: c
      publicServerUrl: https://c.example.development.run:443
      publicServerUrlTcp: tcp://c-tcp.example.development.run:443

```

From here, you choose the security mode and define how nodes join the topology.

```yaml
automaticClusterSetup:      
    leader: a                   
    watchers: [c]
    clientCertSecretRef: ravendb-client-cert
    caCertSecretRef: ravendb-ca-cert # only for self-signed mode

```

**Notes**

- **Client Certificate is Always Required:**
Both modes require a ClusterAdmin client certificate (clientCertSecretRef). The bootstrapper uses this certificate to authenticate when calling the RavenDB Admin API.

- **CA Certificate Required for Self-Signed Mode only:**
In self-signed deployments, caCertSecretRef must be provided so the bootstrapper can ensure all nodes trust the same CA that issued the server certificates.

- **Leader Selection:**
Exactly one node must be specified as the cluster leader under automaticClusterSetup.leader.

- **Watchers and Members:**
Nodes listed under watchers are added to the cluster as watchers.
Any node not explicitly listed as a leader or watcher will be added as a member automatically.

ðŸ“š For a detailed explanation of cluster roles, topology management, and node responsibilities in RavenDB, see the [official documentation](https://docs.ravendb.net/7.1/server/clustering/overview)


You can find full examples of complete RavenDBCluster custom resources for both modes with automatic cluster setup under the `examples` directory:
- `examples/cluster/ravendb_v1alpha1_ravendbcluster_letsencrypt_cluster.yaml`
- `examples/cluster/ravendb_v1alpha1_ravendbcluster_selfsigned_cluster.yaml`


---

## Example Walkthrough

### Step 1 - Create the namespace and required secrets

First, weâ€™ll set up the namespace and drop in the prerequisites.  
This includes the license, per-node server certificates from the RavenDB setup package, and the ClusterAdmin client certificate the bootstrapper will use.

```bash
kubectl create namespace ravendb

kubectl create secret generic ravendb-license --from-file=license.json=./license.json -n ravendb

kubectl create secret generic ravendb-certs-a --from-file=server.pfx=./setup_package/A/cluster.server.certificate.example.pfx -n ravendb

kubectl create secret generic ravendb-certs-b --from-file=server.pfx=./setup_package/B/cluster.server.certificate.example.pfx -n ravendb

kubectl create secret generic ravendb-certs-c --from-file=server.pfx=./setup_package/C/cluster.server.certificate.example.pfx -n ravendb

kubectl create secret generic ravendb-client-cert --from-file=client.pfx=./setup_package/admin.client.certificate.example.pfx -n ravendb
```

### Step 2 - Apply the cluster CR

Now weâ€™ll apply a `RavenDBCluster` resource that tells the operator:
- "a" is the leader
- "c" is a watcher
- "b" is a member (because it isn't specified as leader or watcher)

```yaml
apiVersion: ravendb.ravendb.io/v1alpha1
kind: RavenDBCluster
metadata:
  labels:
    app.kubernetes.io/name: ravendb-operator
    app.kubernetes.io/managed-by: kustomize
  name: ravendbcluster-sample
  namespace: ravendb
spec:
  nodes:
    - tag: a
      publicServerUrl: https://a.example.development.run:443
      publicServerUrlTcp: tcp://a-tcp.example.development.run:443
      certSecretRef: ravendb-certs-a
    - tag: b
      publicServerUrl: https://b.example.development.run:443
      publicServerUrlTcp: tcp://b-tcp.example.development.run:443
      certSecretRef: ravendb-certs-b
    - tag: c
      publicServerUrl: https://c.example.development.run:443
      publicServerUrlTcp: tcp://c-tcp.example.development.run:443
      certSecretRef: ravendb-certs-c

  automaticClusterSetup:
    leader: a
    watchers: [c]
    clientCertSecretRef: ravendb-client-cert

  image: ravendb/ravendb:latest
  imagePullPolicy: IfNotPresent
  mode: LetsEncrypt
  email: you@example.com
  licenseSecretRef: ravendb-license
  domain: example.development.run
  storage:
    data:
      size: 10Gi
      storageClassName: local-path
```

Apply it: `kubectl apply -f ./ravendbcluster.yaml`


### Step 3 - Watch the pods and logs

A few seconds later youâ€™ll see all three RavenDB pods, plus a short-lived cluster-init pod:

```bash
$ kubectl get pods -n ravendb

ravendb   ravendb-a-0                    1/1   Running    0   7s
ravendb   ravendb-b-0                    1/1   Running    0   7s
ravendb   ravendb-c-0                    1/1   Running    0   7s
ravendb   ravendb-cluster-init-88w6m     1/1   Running    0   7s
```
That ravendb-cluster-init-* pod is the bootstrapper job - itâ€™s going to wait for all pods, check their HTTPS reachability, upload the client cert to the leader, and then join the nodes.
You can peek at the bootstrapper logs to see him in action:

```
$ kubectl get logs -n ravendb ravendb-cluster-init-88w6m

>> Starting RavenDB cluster bootstrapper...
[07:56:32] === Starting Discoverability Checks ===
[07:56:32] Checking if kubectl is already installed...
[07:56:32] Downloading and installing kubectl...
[07:56:36] kubectl installed successfully.
[07:56:36] Waiting for all RavenDB pods to be in 'Running' state...
[07:56:36] Pod readiness check: attempt 1/30
[07:56:36] Waiting for these pods to be ready:
[07:56:36] ravendb-a-0 Pending
		   ravendb-b-0 Pending
		   ravendb-c-0 Pending
[07:56:41] Pod readiness check: attempt 2/30
[07:56:41] All RavenDB pods are running.
[07:56:41] Checking HTTPS (Studio) reachability of RavenDB nodes...
[07:56:41] [a] curl -k https://a.thegoldenplatypus.development.run:443
[07:56:41] [a] Studio redirect detected - looks good
[07:56:41] [c] curl -k https://c.thegoldenplatypus.development.run:443
[07:56:41] [c] Studio redirect detected - looks good
[07:56:41] [b] curl -k https://b.thegoldenplatypus.development.run:443
[07:56:41] [b] Studio redirect detected - looks good
[07:56:41] === Discoverability Checks Completed ===
[07:56:41] === Starting Cluster Initialization ===
[07:56:41] Converting /ravendb/certs/server.pfx to PEM and KEY...
[07:56:41] Converting /ravendb/client-certs/client.pfx to PEM and KEY...
[07:56:41] Registering Admin client certificate...
[07:56:42] Admin certificate registered.
[07:56:43] [C] added as Watcher
[07:56:47] [B] added as Member
[07:56:50] Cluster topology:
{
  "Leader": "A",
  "CurrentState": "Leader",
  "CurrentTerm": 1,
  "TopologyId": "30a89961-3931-4fb1-85a1-6aa119235b98",
  "Members": "A B",
  "Watchers": "C"
}

[07:56:50] === Cluster Initialization Complete ===
```

Once the bootstrapper finishes, itâ€™ll mark the job as Completed and disappear. The three RavenDB nodes keep running:

```bash
$ kubectl get pods -n ravendb
ravendb   ravendb-a-0                    1/1   Running     0   29s
ravendb   ravendb-b-0                    1/1   Running     0   29s
ravendb   ravendb-c-0                    1/1   Running     0   29s
ravendb   ravendb-cluster-init-88w6m     0/1   Completed   0   29s
```